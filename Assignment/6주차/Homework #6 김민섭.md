## 6주차 머신러닝 과제

2023170864 김민섭

---

**1. 의사결정트리 개요**
의사결정트리는 각 데이터의 속성을 기준으로 규칙을 만들고, 이를 바탕으로 데이터를 단계적으로 나누어 분류나 수치 예측을 수행하는 지도 학습 모델이다. 범주형과 연속형 데이터를 모두 다룰 수 있으며, 데이터 분포에 대한 가정이 필요 없는 비모수 모델로 해석이 쉽다.

---

**2. 분류와 회귀에서의 차이**
분류에서는 새로운 샘플이 도달한 끝마디에 속한 학습 샘플의 범주 빈도를 보고, 가장 빈도가 높은 범주를 예측값으로 삼는다. 회귀에서는 끝마디에 속한 샘플의 종속 변수 평균을 예측값으로 사용하며, 각 끝마디마다 하나의 수치 예측값을 갖는다.

---

**3. 결정트리 훈련 및 활용 과정**

1. **의사결정나무 형성**

   - 분리 기준: 부모마디에서 어떤 특성과 기준값으로 분할할지 정하며, 마디의 순수도를 최대화하도록 한다.
   - 정지 규칙: 트리 깊이, 최소 샘플 수, 순수도 변화 여부 등을 보고 더 이상 분할하지 않을 조건을 설정한다.

2. **가지치기**

   - 학습 데이터에 과도하게 맞춘 분기를 제거해 트리 복잡도를 줄이고, 새로운 데이터에 대한 일반화 성능을 높인다.

3. **타당성 평가 및 예측**

   - 교차 검증 등으로 학습된 트리의 성능을 확인한 뒤, 새로운 데이터에 대해 분기 경로를 따라 예측값을 계산한다.

---

**4. 장단점**

- **장점**

  1. 해석 용이성: 트리 구조를 따라가면 어떤 기준으로 나뉘었는지 단계별로 알 수 있어 모델의 판단 근거를 쉽게 이해할 수 있다.
  2. 교호작용 파악: 여러 특성이 결합해 결과에 미치는 영향을 분기 경로에서 바로 확인할 수 있다.
  3. 비모수 특성: 데이터 분포에 대한 가정이 필요 없어 다양한 형태의 자료를 전처리 없이도 적용할 수 있다.

- **단점**

  1. 경계 민감성: 연속형 특성을 하나의 기준값으로만 나누기 때문에 기준 주변에서 예측 오차가 커질 수 있다.
  2. 전체 영향력 해석 어려움: 각 분기는 지역적 규칙만 제시하므로 모든 특성의 전반적 영향을 파악하기 어렵다.
  3. 불안정성: 학습 데이터가 조금만 바뀌어도 트리 구조가 크게 달라져 예측 결과가 불안정해질 수 있다.

---

**5. CART 알고리즘**
CART 알고리즘은 분류와 회귀 문제에 모두 사용할 수 있으며, 각 노드에서 분할 전후의 불순도 합이 최소가 되도록 특성과 기준값을 선택해 데이터를 나눈다. 비용 함수는 마디의 불순도를 합산한 값으로, 이를 최소화해야 자식 마디가 더 순수해진다. 분할 과정에서는 트리 최대 깊이나 최소 샘플 수 같은 제한 조건을 만족하거나 더 이상 불순도가 줄지 않을 때까지 반복한다.

---

**6. 지니 불순도 vs. 엔트로피**

- **지니 불순도**

  $$
  G_i = 1 - \sum_{k=1}^{K} p_{i,k}^2
  $$

  마디 내에서 특정 범주가 차지하는 비율을 제곱해 합산한 뒤 1에서 빼서 계산한다.

- **엔트로피**

  $$
  H_i = -\sum_{k=1}^{K} p_{i,k} \log(p_{i,k})
  $$

  마디 내 범주별 비율에 로그를 곱해 합산한 뒤 부호를 바꿔 계산한다.

사이킷런 결정트리 분류기의 기본 기준은 지니 지수이며, 엔트로피를 사용하려면 별도 옵션을 지정해야 한다. 엔트로피 방식은 다소 균형 잡힌 분기를 만들기도 하지만 실제 성능 차이는 크지 않고, 지니 지수가 계산이 더 빠르므로 기본으로 많이 사용된다.

---
